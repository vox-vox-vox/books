# 代码暂存器

暂存一些有点意义的代码

暂存一下自己写过的递归版本找最近的节点的代码：

```go
func getSimpleNodeIndex(nodes *[]*types.FlowNode ,edges *map[int]map[int]int ,nextSimpleNodes *map[int]map[string]int ,nodeIndex int)(set map[string]int){
	nextNodes := (*edges)[nodeIndex]				// 当前节点的下一个节点集合
	nextSimpleNodesCurr := make(map[string]int) 		// 下一个simple nodes 的 set, value维度没有意义全部为0
	if len(nextNodes) == 0 {							// 最后一个节点, 插入一个空set
		(*nextSimpleNodes)[nodeIndex] = nextSimpleNodesCurr
		return nextSimpleNodesCurr
	}
	switch (*nodes)[nodeIndex].DataType {
	case "FORK_JOIN","DECISION":
		if (*nextSimpleNodes)[nodeIndex]!=nil{
			return (*nextSimpleNodes)[nodeIndex]
		}
		for k,_ := range nextNodes {
			mergeBtoA(&nextSimpleNodesCurr,getSimpleNodeIndex(nodes,edges,nextSimpleNodes,k))
		}
		(*nextSimpleNodes)[nodeIndex]=nextSimpleNodesCurr
		return nextSimpleNodesCurr
	case "HTTP","SIMPLE":
		for k,_ := range nextNodes {
			mergeBtoA(&nextSimpleNodesCurr,getSimpleNodeIndex(nodes,edges,nextSimpleNodes,k))
		}
		(*nextSimpleNodes)[nodeIndex]=nextSimpleNodesCurr
		return map[string]int{
			(*nodes)[nodeIndex].RefName:0,
		}
	case "LOOP_END":
		//由于底层是map，因此无法得到最大的key，需要多做一步处理.LOOP_END 节点一共就两个子节点，一个指向之前的，一个指向之后的，我们只要指向之后的。
		for k,_ := range nextNodes {
			if k>nodeIndex{
				mergeBtoA(&nextSimpleNodesCurr,getSimpleNodeIndex(nodes,edges,nextSimpleNodes,k))
			}
		}
		(*nextSimpleNodes)[nodeIndex]=nextSimpleNodesCurr
		return nextSimpleNodesCurr
	default://"DO_WHILE"/"WAIT"/stateChange/decisionBranch/start/end
		for k,_ := range nextNodes {
			mergeBtoA(&nextSimpleNodesCurr,getSimpleNodeIndex(nodes,edges,nextSimpleNodes,k))
		}
		(*nextSimpleNodes)[nodeIndex]=nextSimpleNodesCurr
		return nextSimpleNodesCurr
	}

}
func linkLoopEnd(nodes *[]*types.FlowNode ,edges *map[int]map[int]int ,nextSimpleNodes *map[int]map[string]int ,doWhileList *map[int]int,nodeIndex int,maxLoopEnd int)(set map[string]int){
	nextNodes := (*edges)[nodeIndex]				// 当前节点的下一个节点集合
	nextSimpleNodesCurr := make(map[string]int) 		// 下一个simple nodes 的 set, value维度没有意义全部为0
	switch (*nodes)[nodeIndex].DataType {
	case "FORK_JOIN","DECISION":
		for k,_ := range nextNodes {
			mergeBtoA(&nextSimpleNodesCurr,linkLoopEnd(nodes,edges,nextSimpleNodes,doWhileList,k,maxLoopEnd))
		}
		(*nextSimpleNodes)[nodeIndex]=nextSimpleNodesCurr
		return nextSimpleNodesCurr
	case "HTTP","SIMPLE":
		for k,_ := range nextNodes {
			mergeBtoA(&nextSimpleNodesCurr,linkLoopEnd(nodes,edges,nextSimpleNodes,doWhileList,k,maxLoopEnd))
		}
		(*nextSimpleNodes)[nodeIndex]=nextSimpleNodesCurr
		return map[string]int{
			(*nodes)[nodeIndex].RefName:0,
		}
	case "LOOP_END":
		//连接循环部分
		for k,_ := range nextNodes {
			if nodeIndex==maxLoopEnd&&k>nodeIndex{
				continue//如果已经到达了最后一个loopEnd，就不进行最后一个LOOP_END下面节点的更新
			}
			mergeBtoA(&nextSimpleNodesCurr,linkLoopEnd(nodes,edges,nextSimpleNodes,doWhileList,k,maxLoopEnd))
		}
		(*nextSimpleNodes)[nodeIndex]=nextSimpleNodesCurr
		return nextSimpleNodesCurr
	case "DO_WHILE":
		if (*doWhileList)[nodeIndex]>=0{
			for k,_ := range nextNodes {
				linkLoopEnd(nodes,edges,nextSimpleNodes,doWhileList,k,maxLoopEnd) //仅递归但不更新
			}
			(*doWhileList)[nodeIndex]--
			return (*nextSimpleNodes)[nodeIndex] //因为getSimpleNodeIndex已经有了值，就直接返回
		}else{
			return (*nextSimpleNodes)[nodeIndex] //停止递归，直接返回
		}
	default://"DO_WHILE"/"WAIT"/stateChange/decisionBranch/start/end
		for k,_ := range nextNodes {
			mergeBtoA(&nextSimpleNodesCurr,linkLoopEnd(nodes,edges,nextSimpleNodes,doWhileList,k,maxLoopEnd))
		}
		(*nextSimpleNodes)[nodeIndex]=nextSimpleNodesCurr
		return nextSimpleNodesCurr
	}

}



	//getSimpleNodeIndex(&resp.FlowNode,&edges,&nextSimpleNodes,0)
	//
	//doWhileLists:=make(map[int]int)// key：doWhile节点的index value：doWhile节点的可访问次数，为0时停止递归，初始值均设为1
	//lastLoopEnd:=0
	//firstDoWhile:=100000 // 随便设一个很大的数
	//for index,node := range resp.FlowNode{
	//	if node.DataType=="LOOP_END"{
	//		if index>lastLoopEnd{
	//			lastLoopEnd=index
	//		}
	//	}else if node.DataType=="DO_WHILE"{
	//		if index<firstDoWhile{
	//			firstDoWhile=index
	//		}
	//		doWhileLists[index] = 1
	//	}
	//}
	//// 有DoWhile节点才进行连接
	//if firstDoWhile!=100000{
	//	linkLoopEnd(&resp.FlowNode,&edges,&nextSimpleNodes,&doWhileLists,firstDoWhile,lastLoopEnd)
	//}



	// scheduleEvents 					event表
	// edges							图
	// resp.FlowNodes					Node 数组
	// nextSimpleNodes					key index    value 下一个simple组成的set 里面放的是ref-name







		switch node.DataType {
			case "SIMPLE","HTTP":
				subNodeIndex:=(*edges)[nodeIndex]
				for k,_ := range subNodeIndex{
					if node.Status=="COMPLETED"||node.Status=="SKIPPED"{
						dealSubNode(nodes,nodeIndex,k,edgeOutputMap,visitCount)
						queue.PushBack(k)
					}else{
						queue.PushBack(k)
					}
				}
			case "DECISION":
				if node.Status=="COMPLETED"{
					subNodeIndex:=(*edges)[nodeIndex]
					isDefault:=true						//是否是default 的标志位
					var defaultNode *types.FlowNode
					var defaultNodeIndex int
					//下面的for循环不更新default
					for k,_ := range subNodeIndex{
						subNode := (*nodes)[k]
						if subNode.Name=="defaultCase"{
							defaultNode=subNode
							defaultNodeIndex=k
							queue.PushBack(k)
							continue
						}
						if subNode.Status=="COMPLETED"{
							isDefault=false
							(*edgeOutputMap)[strconv.Itoa(nodeIndex)+"to"+strconv.Itoa(k)].Used=true
						}
						queue.PushBack(k)
					}
					//下面才开始更新default
					if isDefault{			//如果确实是没有一个符合的，就是default
						defaultNode.Status="COMPLETED"//设置default节点为completed
						(*edgeOutputMap)[strconv.Itoa(nodeIndex)+"to"+strconv.Itoa(defaultNodeIndex)].Used=true
					}
				}else{
					//如果DECISION也失败，那他的子节点肯定全部失败
					subNodeIndex:=(*edges)[nodeIndex]
					for k,_ := range subNodeIndex{
						queue.PushBack(k)
					}
				}
			case "LOOP_END":
				if node.Status=="COMPLETED"{
					subNodeIndex:=(*edges)[nodeIndex]
					for k,_ := range subNodeIndex{
						subNode := (*nodes)[k]
						if k < nodeIndex{		// subNode是nodeIndex上面的节点，此时subNode必为DO_WHILE节点
							if subNode.LoopCount>0{//如果存在循环
								(*edgeOutputMap)[strconv.Itoa(nodeIndex)+"to"+strconv.Itoa(k)].Used=true
								//不放入队列
							}
						}else{					// subNode是nodeIndex下面的节点，此时subNode仍有可能是dull或者simple节点
							if subNode.DataType=="SIMPLE"||subNode.DataType=="HTTP"{		// dull-->simple
								if subNode.Status=="COMPLETED"||subNode.Status=="SKIPPED"{
									(*edgeOutputMap)[strconv.Itoa(nodeIndex)+"to"+strconv.Itoa(k)].Used=true
								}
								queue.PushBack(k)
							}else{ // dull--->Dull
								subNode.Status="COMPLETED"//如果上一个dull完成，那么他的子节点一定完成
								(*edgeOutputMap)[strconv.Itoa(nodeIndex)+"to"+strconv.Itoa(k)].Used=true
								queue.PushBack(k)
							}
						}
					}
				}else{
					//如果LOOP_END也失败，那他的子节点肯定全部失败
					subNodeIndex:=(*edges)[nodeIndex]
					for k,_ := range subNodeIndex{
						if k>nodeIndex{
							queue.PushBack(k)				//不继续访问上方DO_WHILE节点
						}
					}
				}
			default:
				if node.Status=="COMPLETED"{
					subNodeIndex:=(*edges)[nodeIndex]
					for k,_ := range subNodeIndex{
						subNode := (*nodes)[k]
						if subNode.DataType=="SIMPLE"||subNode.DataType=="HTTP"{		// dull-->simple
							if subNode.Status=="COMPLETED"||subNode.Status=="SKIPPED"{
								(*edgeOutputMap)[strconv.Itoa(nodeIndex)+"to"+strconv.Itoa(k)].Used=true
							}
						}else{ // dull--->dull
							subNode.Status="COMPLETED"//如果上一个dull完成，那么他的子节点一定完成
							(*edgeOutputMap)[strconv.Itoa(nodeIndex)+"to"+strconv.Itoa(k)].Used=true
						}
						queue.PushBack(k)
					}
				}else{
					//如果dull都失败，那他的子节点肯定全部失败
					subNodeIndex:=(*edges)[nodeIndex]
					for k,_ := range subNodeIndex{
						queue.PushBack(k)
					}
				}
		}


































func matchFormHistory(	nodes 				*[]*types.FlowNode ,
						nextSimpleNodes 	*map[int]*map[string]int,
						taskInfo 			TaskInfo,
						scheduleEvents 		*[]*shared.HistoryEvent,
						getIndex			*map[string]int,
						getFather 			*map[int]int,
						getDoWhile			*map[string]int,
						wfID 				string,
						runID 				string) error{
	matchSet:=make(map[string]int)//匹配Set
	mergeBtoA(&matchSet,*(*nextSimpleNodes)[0])
	pattern:=regexp.MustCompile(`(.*)_(\d)`)
	//todo:存在一个问题，如果任务的refName也是以 "_xxx" 结尾的，会出现错误。所以要坚决限制任务的refName
	for _,event:=range *scheduleEvents{
		loopTime:=0
		activityName:=*(event.ActivityTaskScheduledEventAttributes.ActivityId)
		res := pattern.FindStringSubmatch(activityName)
		if res!=nil{
			activityName=res[1]
			loopTime,_=strconv.Atoi(res[2])
		}
		attr:=event.ActivityTaskScheduledEventAttributes
		_,ok:= matchSet[activityName]
		if ok{
			matchedNodeIndex,_:=(*getIndex)[activityName]
			matchedNode:=(*nodes)[matchedNodeIndex]
			fatherNodeIndex:=(*getFather)[matchedNodeIndex]
			fatherNode:=(*nodes)[fatherNodeIndex]
			// 如果已经进入loop,则更新对应DO_WHILE的loopCount
			if loopTime!=0 {
				doWhileIndex:=(*getDoWhile)[activityName]
				(*nodes)[doWhileIndex].LoopCount=loopTime
			}
			if fatherNode.DataType==decisionBranch{ //如果父节点是decisionBranch，还要更新父节点的loopCount
				fatherNode.Status="COMPLETED"
				fatherNode.LoopCount=loopTime
			}

			//stateChange
			// 开始写入
			taskID:=workflow.TaskID{}
			taskID.WorkflowID=wfID
			taskID.RunID=runID
			taskID.Attempt = taskInfo.taskAttempt[matchedNode.RefName]
			taskID.TaskName = *attr.ActivityType.Name //node.Name
			taskID.ActivityID = *attr.ActivityId      //node.RefName
			matchedNode.TaskID = taskID.String()
			if startTime, ok := taskInfo.taskStartTime[matchedNode.RefName]; ok {
				tm := time.Unix(0, startTime)
				loc, _ := time.LoadLocation("Asia/Chongqing")
				matchedNode.NodeConf = append(matchedNode.NodeConf, &types.FlowNodeConf{Label: "StartTime", Value: tm.In(loc).String()})
			}
			if endTime, ok := taskInfo.taskEndTime[matchedNode.RefName]; ok {
				tm := time.Unix(0, endTime)
				loc, _ := time.LoadLocation("Asia/Chongqing")
				matchedNode.NodeConf = append(matchedNode.NodeConf, &types.FlowNodeConf{Label: "EndTime", Value: tm.In(loc).String()})
			}
			matchedNode.NodeConf = append(matchedNode.NodeConf, &types.FlowNodeConf{Label: "Input", Value: string(attr.Input)})
			matchedNode.NodeConf = append(matchedNode.NodeConf, &types.FlowNodeConf{Label: "Output", Value: taskInfo.taskResult[matchedNode.RefName]})
			matchedNode.NodeConf = append(matchedNode.NodeConf, &types.FlowNodeConf{Label: "ScheduleToCloseTimeoutSeconds", Value: attr.GetScheduleToCloseTimeoutSeconds()})
			matchedNode.NodeConf = append(matchedNode.NodeConf, &types.FlowNodeConf{Label: "ScheduleToStartTimeoutSeconds", Value: attr.GetScheduleToStartTimeoutSeconds()})
			matchedNode.NodeConf = append(matchedNode.NodeConf, &types.FlowNodeConf{Label: "StartToCloseTimeoutSeconds", Value: attr.GetStartToCloseTimeoutSeconds()})
			matchedNode.NodeConf = append(matchedNode.NodeConf, &types.FlowNodeConf{Label: "HeartbeatTimeoutSeconds", Value: attr.GetHeartbeatTimeoutSeconds()})
			matchedNode.NodeConf = append(matchedNode.NodeConf, &types.FlowNodeConf{Label: "DecisionTaskCompletedEventId", Value: attr.GetDecisionTaskCompletedEventId()})
			matchedNode.NodeConf = append(matchedNode.NodeConf, &types.FlowNodeConf{Label: "RetryPolicy", Value: attr.RetryPolicy})
			matchedNode.NodeConf = append(matchedNode.NodeConf, &types.FlowNodeConf{Label: "Header", Value: attr.Header})
			if taskError, ok := taskInfo.taskErrorsMap[matchedNode.RefName]; !ok {
				matchedNode.Status = taskInfo.taskStatus[matchedNode.RefName]
			} else {
				matchedNode.Status = taskInfo.taskStatus[matchedNode.RefName] //types.FlowNodeFailStatus
				matchedNode.NodeConf = append(matchedNode.NodeConf, &types.FlowNodeConf{Label: "Reasons", Value: taskError["details"]})
				matchedNode.NodeConf = append(matchedNode.NodeConf, &types.FlowNodeConf{Label: "ErrorType", Value: taskError["reason"]})
				matchedNode.NodeConf = append(matchedNode.NodeConf, &types.FlowNodeConf{Label: "Owner", Value: taskInfo.failedTaskOwner})
			}
			// 匹配结束，更新Set
			delete(matchSet,activityName)
			mergeBtoA(&matchSet,*(*nextSimpleNodes)[matchedNodeIndex])
		}else{
			return fmt.Errorf("match failed")
		}
	}
	return nil
}




```









```shell
/home/hzy$
>  echo "GET http://localhost:7900/api/v1/workflows/hx_testQuery_complex3_hhxx:07b7481d-b3b1-4cda-afce-9769dcd2b34c/chart?workflowId=hx_testQuery_complex3_hhxx%3A07b7481d-b3b1-4cda-afce-9769dcd2b34c&run_id=1420d94e-16dc-4cba-b9ad-fde8abce559d" | vegeta attack  -rate=100  -duration=30s |vegeta report
Requests      [total, rate]            3000, 100.04
Duration      [total, attack, wait]    31.93874089s, 29.989216519s, 1.949524371s
Latencies     [mean, 50, 95, 99, max]  1.261132367s, 925.413972ms, 3.323530789s, 3.946123113s, 5.004598945s
Bytes In      [total, mean]            588000, 196.00
Bytes Out     [total, mean]            0, 0.00
Success       [ratio]                  0.00%
Status Codes  [code:count]             500:3000
Error Set:
500 Internal Server Error
/home/hzy$
>  echo "GET http://localhost:7900/api/v1/workflows/hx_testQuery_complex3_hhxx:07b7481d-b3b1-4cda-afce-9769dcd2b34c/chart?workflowId=hx_testQuery_complex3_hhxx%3A07b7481d-b3b1-4cda-afce-9769dcd2b34c&run_id=1420d94e-16dc-4cba-b9ad-fde8abce559d" | vegeta attack  -rate=100  -duration=1s |vegeta report
Requests      [total, rate]            100, 101.01
Duration      [total, attack, wait]    1.042945211s, 990.018343ms, 52.926868ms
Latencies     [mean, 50, 95, 99, max]  71.348242ms, 57.999067ms, 134.585314ms, 166.388761ms, 179.82792ms
Bytes In      [total, mean]            5508000, 55080.00
Bytes Out     [total, mean]            0, 0.00
Success       [ratio]                  100.00%
Status Codes  [code:count]             200:100
Error Set:
/home/hzy$
>  echo "GET http://localhost:7900/api/v1/workflows/hx_testQuery_complex3_hhxx:07b7481d-b3b1-4cda-afce-9769dcd2b34c/chart?workflowId=hx_testQuery_complex3_hhxx%3A07b7481d-b3b1-4cda-afce-9769dcd2b34c&run_id=1420d94e-16dc-4cba-b9ad-fde8abce559d" | vegeta attack  -rate=100  -duration=30s |vegeta report
Requests      [total, rate]            3000, 100.03
Duration      [total, attack, wait]    30.044187359s, 29.990054683s, 54.132676ms
Latencies     [mean, 50, 95, 99, max]  65.647892ms, 57.588527ms, 99.103153ms, 161.012508ms, 286.51561ms
Bytes In      [total, mean]            165240000, 55080.00
Bytes Out     [total, mean]            0, 0.00
Success       [ratio]                  100.00%
Status Codes  [code:count]             200:3000
Error Set:
/home/hzy$
>  echo "GET http://localhost:7900/api/v1/workflows/hx_testQuery_complex3_hhxx:07b7481d-b3b1-4cda-afce-9769dcd2b34c/chart?workflowId=hx_testQuery_complex3_hhxx%3A07b7481d-b3b1-4cda-afce-9769dcd2b34c&run_id=1420d94e-16dc-4cba-b9ad-fde8abce559d" | vegeta attack  -rate=100  -duration=30s |vegeta report
Requests      [total, rate]            3000, 100.04
Duration      [total, attack, wait]    30.049809704s, 29.988807394s, 61.00231ms
Latencies     [mean, 50, 95, 99, max]  83.688244ms, 62.337318ms, 176.647181ms, 215.051599ms, 329.903765ms
Bytes In      [total, mean]            333201000, 111067.00
Bytes Out     [total, mean]            0, 0.00
Success       [ratio]                  100.00%
Status Codes  [code:count]             200:3000
Error Set:
/home/hzy$
>  echo "GET http://localhost:7900/api/v1/workflows/hx_testQuery_complex3_hhxx:07b7481d-b3b1-4cda-afce-9769dcd2b34c/chart?workflowId=hx_testQuery_complex3_hhxx%3A07b7481d-b3b1-4cda-afce-9769dcd2b34c&run_id=1420d94e-16dc-4cba-b9ad-fde8abce559d" | vegeta attack  -rate=100  -duration=30s |vegeta report
Requests      [total, rate]            3000, 100.03
Duration      [total, attack, wait]    30.053041431s, 29.990709678s, 62.331753ms
Latencies     [mean, 50, 95, 99, max]  77.941135ms, 61.985878ms, 170.371333ms, 202.920598ms, 452.823137ms
Bytes In      [total, mean]            333201000, 111067.00
Bytes Out     [total, mean]            0, 0.00
Success       [ratio]                  100.00%
Status Codes  [code:count]             200:3000
Error Set:
/home/hzy$
>  echo "GET http://localhost:7900/api/v1/workflows/hx_testQuery_complex3_hhxx:07b7481d-b3b1-4cda-afce-9769dcd2b34c/chart?workflowId=hx_testQuery_complex3_hhxx%3A07b7481d-b3b1-4cda-afce-9769dcd2b34c&run_id=1420d94e-16dc-4cba-b9ad-fde8abce559d" | vegeta attack  -rate=100  -duration=30s |vegeta report
Requests      [total, rate]            3000, 100.03
Duration      [total, attack, wait]    30.046351154s, 29.990006674s, 56.34448ms
Latencies     [mean, 50, 95, 99, max]  76.97576ms, 61.094465ms, 176.862058ms, 217.862025ms, 279.483124ms
Bytes In      [total, mean]            333201000, 111067.00
Bytes Out     [total, mean]            0, 0.00
Success       [ratio]                  100.00%
Status Codes  [code:count]             200:3000
Error Set:
/home/hzy$
>  echo "GET http://localhost:7900/api/v1/workflows/hx_testQuery_complex3_hhxx:07b7481d-b3b1-4cda-afce-9769dcd2b34c/chart?workflowId=hx_testQuery_complex3_hhxx%3A07b7481d-b3b1-4cda-afce-9769dcd2b34c&run_id=1420d94e-16dc-4cba-b9ad-fde8abce559d" | vegeta attack  -rate=100  -duration=30s |vegeta report
^CRequests      [total, rate]            367, 100.26
Duration      [total, attack, wait]    3.730327565s, 3.660604289s, 69.723276ms
Latencies     [mean, 50, 95, 99, max]  76.451989ms, 62.250644ms, 171.333178ms, 212.633449ms, 239.4468ms
Bytes In      [total, mean]            40761589, 111067.00
Bytes Out     [total, mean]            0, 0.00
Success       [ratio]                  100.00%
Status Codes  [code:count]             200:367
Error Set:
/home/hzy$
>  echo "GET http://localhost:7900/api/v1/workflows/hx_testQuery_complex3_hhxx:07b7481d-b3b1-4cda-afce-9769dcd2b34c/chart?workflowId=hx_testQuery_complex3_hhxx%3A07b7481d-b3b1-4cda-afce-9769dcd2b34c&run_id=1420d94e-16dc-4cba-b9ad-fde8abce559d" | vegeta attack  -rate=150  -duration=30s |vegeta report
Requests      [total, rate]            4500, 150.03
Duration      [total, attack, wait]    30.087456702s, 29.993418532s, 94.03817ms
Latencies     [mean, 50, 95, 99, max]  101.758912ms, 72.32923ms, 213.886736ms, 249.899341ms, 492.725528ms
Bytes In      [total, mean]            499801500, 111067.00
Bytes Out     [total, mean]            0, 0.00
Success       [ratio]                  100.00%
Status Codes  [code:count]             200:4500
Error Set:
/home/hzy$
>  echo "GET http://localhost:7900/api/v1/workflows/hx_testQuery_complex3_hhxx:07b7481d-b3b1-4cda-afce-9769dcd2b34c/chart?workflowId=hx_testQuery_complex3_hhxx%3A07b7481d-b3b1-4cda-afce-9769dcd2b34c&run_id=1420d94e-16dc-4cba-b9ad-fde8abce559d" | vegeta attack  -rate=150  -duration=30s |vegeta report
Requests      [total, rate]            4500, 150.04
Duration      [total, attack, wait]    30.044270496s, 29.992426063s, 51.844433ms
Latencies     [mean, 50, 95, 99, max]  65.975381ms, 57.418142ms, 95.460966ms, 159.171153ms, 1.078722097s
Bytes In      [total, mean]            247860000, 55080.00
Bytes Out     [total, mean]            0, 0.00
Success       [ratio]                  100.00%
Status Codes  [code:count]             200:4500
Error Set:
/home/hzy$
>  echo "GET http://localhost:7900/api/v1/workflows/hx_testQuery_complex3_hhxx:07b7481d-b3b1-4cda-afce-9769dcd2b34c/chart?workflowId=hx_testQuery_complex3_hhxx%3A07b7481d-b3b1-4cda-afce-9769dcd2b34c&run_id=1420d94e-16dc-4cba-b9ad-fde8abce559d" | vegeta attack  -rate=150  -duration=30s |vegeta report
Requests      [total, rate]            4500, 150.03
Duration      [total, attack, wait]    30.050414581s, 29.993183931s, 57.23065ms
Latencies     [mean, 50, 95, 99, max]  64.864939ms, 56.857526ms, 94.54749ms, 147.500354ms, 268.871458ms
Bytes In      [total, mean]            247860000, 55080.00
Bytes Out     [total, mean]            0, 0.00
Success       [ratio]                  100.00%
Status Codes  [code:count]             200:4500
Error Set:
/home/hzy$
>  echo "GET http://localhost:7900/api/v1/workflows/hx_testQuery_complex3_hhxx:07b7481d-b3b1-4cda-afce-9769dcd2b34c/chart?workflowId=hx_testQuery_complex3_hhxx%3A07b7481d-b3b1-4cda-afce-9769dcd2b34c&run_id=1420d94e-16dc-4cba-b9ad-fde8abce559d" | vegeta attack  -rate=300  -duration=30s |vegeta report
Requests      [total, rate]            9000, 300.03
Duration      [total, attack, wait]    30.063826783s, 29.996578247s, 67.248536ms
Latencies     [mean, 50, 95, 99, max]  73.922219ms, 68.194961ms, 140.025901ms, 201.813725ms, 319.047269ms
Bytes In      [total, mean]            495720000, 55080.00
Bytes Out     [total, mean]            0, 0.00
Success       [ratio]                  100.00%
Status Codes  [code:count]             200:9000
Error Set:
/home/hzy$
>  echo "GET http://localhost:7900/api/v1/workflows/hx_testQuery_complex3_hhxx:07b7481d-b3b1-4cda-afce-9769dcd2b34c/chart?workflowId=hx_testQuery_complex3_hhxx%3A07b7481d-b3b1-4cda-afce-9769dcd2b34c&run_id=1420d94e-16dc-4cba-b9ad-fde8abce559d" | vegeta attack  -rate=300  -duration=30s |vegeta report
Requests      [total, rate]            9000, 300.03
Duration      [total, attack, wait]    30.058558643s, 29.996581494s, 61.977149ms
Latencies     [mean, 50, 95, 99, max]  72.760299ms, 68.304365ms, 131.610899ms, 187.269914ms, 277.629583ms
Bytes In      [total, mean]            495720000, 55080.00
Bytes Out     [total, mean]            0, 0.00
Success       [ratio]                  100.00%
Status Codes  [code:count]             200:9000
Error Set:
/home/hzy$
>  echo "GET http://localhost:7900/api/v1/workflows/hx_testQuery_complex3_hhxx:07b7481d-b3b1-4cda-afce-9769dcd2b34c/chart?workflowId=hx_testQuery_complex3_hhxx%3A07b7481d-b3b1-4cda-afce-9769dcd2b34c&run_id=1420d94e-16dc-4cba-b9ad-fde8abce559d" | vegeta attack  -rate=300  -duration=30s |vegeta report
Requests      [total, rate]            9000, 300.04
Duration      [total, attack, wait]    47.889563578s, 29.99595791s, 17.893605668s
Latencies     [mean, 50, 95, 99, max]  8.811591654s, 8.061798965s, 20.655349052s, 22.971521812s, 29.970665293s
Bytes In      [total, mean]            998714464, 110968.27
Bytes Out     [total, mean]            0, 0.00
Success       [ratio]                  99.91%
Status Codes  [code:count]             0:8  200:8992
Error Set:
Get http://localhost:7900/api/v1/workflows/hx_testQuery_complex3_hhxx:07b7481d-b3b1-4cda-afce-9769dcd2b34c/chart?workflowId=hx_testQuery_complex3_hhxx%3A07b7481d-b3b1-4cda-afce-9769dcd2b34c&run_id=1420d94e-16dc-4cba-b9ad-fde8abce559d: net/http: timeout awaiting response headers
```







# 干活暂存器

Etc Redis hosts

ctx deadline 的设置怎样才合理

Future 是干什么的

selector

go mod tidy / go pkg / 走了哪个包

zshrc 中 配置以自动启动ssh `alias`

Ssh-copy-id

Uint8格式的output怎样转换为interface

并发Map里面存的指针所指向的东西是并发安全的吗，为什么需要并发map？

map为什么不能address？map扩容时发生了什么

变量的作用域问题（尤其是error！！！）

脚本的编写

ssh-copy-id





context

rpc，分布式问题，并发问题

query

