---
typora-copy-images-to: upload
---

# 任务编排系统

名词：task=activity，task是任务编排系统的描述，activity是cadence的描述。pod是task的运行环境

# 0. 系统组成

![image-20211105011806778](https://tva1.sinaimg.cn/large/008i3skNly1gw3mhnnf2wj31if0u0djk.jpg)



![E477255F-4CAB-42DC-8A96-0266A9ED29C1](https://tva1.sinaimg.cn/large/008i3skNly1gvutv321ksj30jm0ps3yv.jpg)





![2E48FDFB-79C4-4F7C-A8D8-CD793AC11A3E](https://tva1.sinaimg.cn/large/008i3skNly1gvutusbaqej30ic0qb0t7.jpg)

History：
![image.png](http://47.100.67.5:8090/upload/2021/11/image-10773555495949dd9bd26e7aa5c7fd11.png)

![image.png](http://47.100.67.5:8090/upload/2021/11/image-2b23dee6e5954b85947815473e4300c7.png)

# 1. 功能

基于cadence，实现了任务编排。主要由workflow和activity两部分组成。activity是最小的任务执行单元，代表一种自定义的操作（算法模块、存数据库、人工任务等），不同的activity按照自定义的语义组成了workflow。workflow是一个相对比较大的范畴，比如我要做成一道菜，activity是洗菜，切菜，焯水等步骤，按照这些步骤组成workflow，最后就能做出一道菜来

目前支持的语义：顺序，循环，选择，并行，父子任务

目前支持的操作：skip，reset，retry，restart，terminal

目前为高可用性提供的功能：failHandler（workflow级别），retry（activity级别）

# 2. cadence的特点与机制

我们的编排系统基于cadence，cadence是uber实现的一个分布式高可用中间件，主要有以下特点：

1. 分布式处理，可处理多个并发workflow
2. 错误容忍（Fault tolerant）Cadence 可以编写有状态的应用程序，而无需担心处理流程故障的复杂性。

总的来说，Cadence 利用server端的数据库和history机制，提供了一个持久的虚拟内存，不属于特定进程，保留完整的应用程序状态。状态包括：函数堆栈，局部变量等。

如果workflow执行过程中任一机器出现宕机，此时执行状态仍能被保存。

cadence-replay机制

![image-20211102210017300](https://tva1.sinaimg.cn/large/008i3skNly1gw13sr3ngmj30ms0kltbq.jpg)

# 3. 一次任务调度的过程

workflow创建

dsl解析 sequence(statement[])---statement

任务创建，放入cadence队列中

部署在pod上的worker 进行任务拉取，拉取到后运行业务逻辑

任务完成

workflow中转

workflow完成



# 4. 流程改变

## reset类操作

### 操作示例

<img src="https://tva1.sinaimg.cn/large/008i3skNly1gwvssixgcrj30el0bi74f.jpg" alt="image2021-7-24_15-25-27.png" style="zoom:67%;" />

<img src="https://tva1.sinaimg.cn/large/008i3skNly1gwvsslmxx2j30d40cyglt.jpg" alt="image2021-7-24_15-38-30.png" style="zoom:67%;" />

<img src="https://tva1.sinaimg.cn/large/008i3skNly1gwvssnzvggj30by0dvaab.jpg" alt="image2021-8-17_21-29-24.png" style="zoom:67%;" />

<img src="https://tva1.sinaimg.cn/large/008i3skNly1gwvssqrlrsj30cc0e0q36.jpg" alt="image2021-8-17_21-29-38.png" style="zoom:67%;" />

### 原理

terminate 直接结束流程

retry，restart均基于reset；retry=reset前一个失败的activity；restart=reset第一个activity

reset直接调用接口，cadence内部将 [0,reset处) 的history拷贝到新的workflow中，作为一个新的decisionTask被workflow-worker拉取，然后进行历史重放，重放直至reset处的activity，然后重新进行编排。

<img src="https://tva1.sinaimg.cn/large/008i3skNly1gw13rnd616j30bc0czaan.jpg" alt="image-20211102205911456" style="zoom:80%;" />

​	

## skip类

<img src="https://tva1.sinaimg.cn/large/008i3skNly1gwvssu4wtjj30bq0dst8y.jpg" alt="image2021-8-17_21-29-59.png" style="zoom:67%;" />





# 5. 支持的DSL语义

## simple

最基础的工作单位，非逻辑节点。

## loop

![image-20211103111411580](https://tva1.sinaimg.cn/large/008i3skNly1gw1sh8gc0ij309402v0sp.jpg)

```json
{
  "name": "common_do_while",
  "taskReferenceName": "reference_name", # 对应TaskRefName
  "description": "description",
  "inputParameters": {
    "value": ""
  },
  "loopCondition": "if($.hxTask1Ref.output.status!='success'){true}else{false}", # 对应Condition
  "loopOver": [ # 对应Body
    {
      "name": "hxTask1",
      "taskReferenceName": "hxTask1Ref",
      "description": "description",
      "inputParameters": {},
      "type": "SIMPLE"
    }
  ],
  "type": "DO_WHILE"
}
```



```go
for maxLoopCount
	for in range Body
		body.elements.Execute// 执行所有loop包含的task
	canContinue, err := vm.Run(l.Condition)// 利用js虚拟机计算condition条件
	if !canContinue
		break
```

## decision

![image-20211103111706772](https://tva1.sinaimg.cn/large/008i3skNly1gw1ska3019j309b04kdfw.jpg)

```json
{
  "name": "common_decision",
  "taskReferenceName": "reference_name", # 对应TaskRefName
  "inputParameters": {
    "case_value_param": "${hxTaskMakeInput.output.status}" # 对应Arguments
  },
  "caseValueParam": "case_value_param",	# 对应keyBase
  "type": "DECISION",
  "decisionCases": { # 对应Branches
    "success": [
      {
        "name": "hxTask1",
        "taskReferenceName": "hxTask1Ref",
        "description": "description",
        "inputParameters": {},
        "type": "SIMPLE"
      }
    ],
    "failed": [
      {
        "name": "hxTask2",
        "taskReferenceName": "hxTask2Ref",
        "description": "description",
        "inputParameters": {},
        "type": "SIMPLE"
      }
    ]
  }
}

# default branch 自动添加
```

```go
key = inputParam[caseValueParam] // 众多input中，有一个是表征选择哪个分支的。e.g. key = ”success“ 或 ”failed“
branch,ok = Branches[key] //找到对应的分支
if !ok
	branch=dafaultBranch // 没找到，走default。
branch.Execute // 执行task
```



## dyamic-subworkflow

采用外部实现方式

- 父流程

  <img src="https://tva1.sinaimg.cn/large/008i3skNly1gw23y24n4lj30s30h4t9s.jpg" alt="image-20211103175053071" style="zoom:80%;" />

- 子流程

  <img src="https://tva1.sinaimg.cn/large/008i3skNly1gw2708ugdnj30xy0mewfu.jpg" alt="image-20211103193650973" style="zoom:33%;" />

- 工作逻辑

  ![image-20211105010241024](https://tva1.sinaimg.cn/large/008i3skNly1gw3m1nbo72j31dw0u0q6m.jpg)

  查表判断子流程组是否运行完毕的细节：

  ```go
  /*output: 能否发送信号*/
  func (s *SubWorkflowStore) SubWorkflowComplete(req *types.SubWorkflowReq) (bool, error) {
  
  	success, failed, err := s.GetSubWorkflowNumber(req)
  	if err != nil {
  		return false, err
  	}
  
  	if success+failed < req.Count {
  		return false, nil
  	}
  
  	if req.SuccessPerCent < 0 {
  		req.SuccessPerCent = 0
  	} else if req.SuccessPerCent > 100 {
  		req.SuccessPerCent = 100
  	}
  	return success*100 >= req.Count*req.SuccessPerCent, nil
  }
  
  /*具体查询细节*/
  func (s *SubWorkflowStore) GetSubWorkflowNumber(req *types.SubWorkflowReq) (successNumber, failedNumber int, err error) {
  	result := s.db.Model(&types.SubWorkflow{}).
  		Where("father_workflow_id = ? and father_run_id = ? and son_workflow_id = ?", req.FatherWorkflowID, req.FatherRunID, req.SonWorkflowID).
  		Update("status", req.Status)
  	if result.Error != nil {
  		return 0, 0, result.Error
  	}
  	var successCount, failedCount, terminatedCount int
  	pre := s.db.Model(&types.SubWorkflow{}).Where("father_workflow_id = ? and father_run_id = ?", req.FatherWorkflowID, req.FatherRunID)
  	result = pre.Where("status = ? ", subWorkflowTerminated).Count(&terminatedCount)
  
  	if result.Error != nil {
  		return 0, 0, result.Error
  	}
  	result = pre.Where("status = ? ", subWorkflowSuccess).Count(&successCount)
  	if result.Error != nil {
  		return 0, 0, result.Error
  	}
  	result = pre.Where("status = ? ", subWorkflowFailed).Count(&failedCount)
  	if result.Error != nil {
  		return 0, 0, result.Error
  	}
  	return successCount, failedCount + terminatedCount, nil
  }
  
  ```

## parallel

![image-20211103125220684](https://tva1.sinaimg.cn/large/008i3skNly1gw1vbd2ys1j3098026t8n.jpg)

```go
childCtx, cancelHandler := workflow.WithCancel(ctx)
waitChannel := workflow.NewChannel(childCtx) // 自带ctx取消机制
var activityErr error
for _, s := range p.Branches {
  state := s
  workflow.Go(childCtx, func(childCtx workflow.Context) { // 开启协程，进行并行任务编排
    err := state.Execute(childCtx, ao, bindings, wfID, runID)
    if err != nil {	// 如果有任务失败了
      if seq, ok := state.(*Sequence); ok {
        act, ok := seq.Elements[0].(*ActivityInvocation)
        if ok && act.Type == TaskTypeSubWorkflow {
          err = nil
        }
      }
    }
    activityErr = err
    waitChannel.Send(childCtx, true)//并行任务完成后发送signal给信道
  })
}

for i := 0; i < len(p.Branches); i++ {
  waitChannel.Receive(childCtx, nil) //信道开始接受
  if activityErr != nil { 
    //waitChannel.Close()
    cancelHandler()	//如果信道收到Err，则直接cancel所有并行协程
    return activityErr
  }
}

```

## http+wait 

http任务和simple一样，都是将activity放入cadence中。不同的是，由于http任务简单，http的activity-worker在system-worker内部实现。

wait：

![image-20211103114128561](https://tva1.sinaimg.cn/large/008i3skNly1gw1t9mnt0ej309e03g749.jpg)

```go
signalName := w.SignalName //实际上就是Wait的ref-name
signalChan := workflow.GetSignalChannel(ctx, signalName) //开启信道，等待
signalChan.Receive(ctx, &signalVal)	//如果信道没有signal，阻塞。这也是wait的实现原理
```

http+wait主要用来实现人工任务：

```
http_task-------------------------------->人工作业平台
		|																					|
进入wait状态																人工作业
		|																					|
唤醒wait,workflow继续	<-----signal------  人工作业结束
```

# 6. 链路参数传递

## task input&task output

对于一个task，可以接受来自两个部分的参数：

- 其他task的output
- workflow的全局参数

具体参数解析：statement 908

## signal

signal是cadence内部提供的一个异步传递信息的机制。业务方通过调用signal接口：

![image-20211105144025671](https://tva1.sinaimg.cn/large/008i3skNgy1gw4jxgz54oj31lo0aqjt5.jpg)

向cadence-server中发送signal。cadence-server将signal转换成decisionTask，供workflow-worker拉取。workflow-worker中提前注册channel，再对signal进行处理。

宏观来看，好像业务方直接向注册的signal-channel中发送了一个信号一样。

![image-20211105145951953](https://tva1.sinaimg.cn/large/008i3skNgy1gw4jwkhyi6j31gu0qatb5.jpg)

### 使用signal机制的例子

- query机制中，task-startTime和task-endTime

  以endTime发送信号为例：

  ```go
  /*Mojito发送signal*/
  activityEndInfo := workflow.ActivityEndInfo{
    EndTime:        time.Now(),
    RefName:        taskRefName,
    ActivityTaskID: checkID,
  }
  err := mojito.GCadenceClientsWithDomain[workflow.CadenceDomain(req.Domain)].SignalWorkflow(&workflow.SignalWorkflowOptions{
    WorkflowID: wfID,
    SignalName: "activityEndInfo",
    SignalArg:  activityEndInfo,
    Domain:     req.Domain,
  })
  if err != nil {
    logger.Errorf("update activity signal for query failed")
  }
  
  /*cadence-system-worker接受*/
  workflow.GoNamed(ctx, _updateStartStatus, func(ctx workflow.Context) {
    sig := workflow.GetSignalChannel(ctx, "activityStartInfo")
    var activityStartInfo ActivityStartInfo
    for{
      more:=sig.Receive(ctx,&activityStartInfo)
      if !more {
        logger.Info("channel closed")
        break
      }
      
      /*写入bindings*/
      
    }
  })
  ```

- Msubstatus

  每次状态改变时，都发送信号，改变当前workflow状态值。具体细节见 [第10部分](##Msubstatus与其存在的数据一致性问题)

- skip

# 7. 数据可靠性的保证

## cadence内部机制保证数据可靠性

cadence内部通过history机制保证了workflow的可靠性

history记录了每一个操作的结果，并在适当的时候进行重放

利用这样的特性，workflow-worker可以分布式地处理同一个workflow，也就为高可用提供了前提保障。只要history记录存在，workflow就能恢复到相应的历史

## workflow失败failure-handler机制



## task失败retry机制

retry实际上就是将activity重新放入队列中

每个activity在scheduled之前，都要加载options，其中就有activity的retry策略：

<img src="https://tva1.sinaimg.cn/large/008i3skNgy1gw4jwvha58j31e80ocjwp.jpg" alt="image-20211105161221174" style="zoom:40%;" />

预先定义好不会被retry的error类型，其余均会被retry

# 8. 缓存机制

## stickyExecution

> workflow只被执行过的worker执行，因为有cache
>
> Sticky Execution is to run the decision tasks for one workflow execution on same worker host. This is an optimization for workflow execution. When sticky execution is enabled, worker keeps the workflow state in memory. **New decision task contains the new history events will be dispatched to the same worker.** If this worker crashes, the sticky decision task will timeout after StickyScheduleToStartTimeout, and cadence server will clear the stickiness for that workflow execution and automatically **reschedule a new decision task** that is available for any worker to pick up and resume the progress.

cadence的缓存机制叫stickyExecution，具体表现为：

1. 相同的workflow用相同的worker来执行，这样可以去掉history-replay的环节，节省时间。Query方法比直接查询history方法要快一些的原理也是这个stickyExecution

2. 何时触发：“New decision task contains the new history events will be dispatched to the same worker.” 也就是说每次有新的decision task时，缓存会生效，请求会被转发至相同的worker，整个过程表现为一种sticky执行。具体来说，触发decisionTask的时机有：query，activityCompleted等。也就是workflow-worker拉取到workflow时，先去检查缓存。

3. 由缓存引申出的高可用问题：decisionTaskA被workflow-workerA拉取到，然后workflow-workerA宕机，此时如果仍使用sticky策略，会导致decisionTaskA无法被任何workflow-worker拉取，此时decisionTask所对应的workflow工作会停止，呈现一种卡死的状态。为了保证高可用，设置一个StickyScheduleToStartTimeout时间，poll decisionTask的时间超过这个阈值时便不执行stickyExecute策略，缓存效果也就不复存在。此时实际上是**重新生成一个不含有cache的decisionTask**，这个decisionTask可以被任意workflow-worker拉取，而不含有cache也代表着整个过程要进行history-replay，此时耗时较长。

4. **stickyScheduledToStartTimeout**指decisionTask在stickExecute过程中**所能接受的耗费的最长时间**，如果过了这个时间（可能是网卡了之类的），decisionTask**就视为原来的sticky-worker已经宕机**，就不会再进行sticky策略。

   - 如果设置的**stickyScheduledToStartTimeout**时间较短（如1s），可能会出现由于workflow-worker并发Query过多，延时过高，导致某次响应decisionTask时间超过1s，此时cadence-server会清除decisionTask的sticky，此时视为workflow-worker已经宕机（实际可能没有宕机），从而造成之后所有的有关该workflow的请求都不会执行stick策略，每一次Query都会新开一个goroutine，造成goroutine泄漏、高latency等现象。
   - 如果设置的**stickyScheduledToStartTimeout**时间较长（如1h），可以避免上述问题，但会出现另一种问题。时间设的过长，如果workflow-worker真的宕机，decisionTask仍将等待1h，此时会造成卡死现象，如果没有新的decisionTask出现来更新sticky绑定关系，当前decisionTask会一直等待，直至1h超时。外部的具体现象表现为，如果一个workflow block在一个activity上很久，此时对应的workflow-worker宕机，之后的decisionTask(包括Query，activityCompleted，都会卡顿1h)

5. 需要注意的是，stickyExecution只与decisionTask有关。具体可表现为，现存在workflow-worker1，workflow-worker2。如果一个decisionTask被workflow-worker1拉到，而此时workflow-worker1宕机，理所应当sticky消失。但是重新来一个新的decisionTask时，会重新与workflow-worker2建立sticky联系，此时重新建立缓存。

   sticky消失以后还能重新获得sticky么，还是永久消失 。sticky不会永久消失。当新来一个decisionTask时，sticky继续生效

## Redis

编排系统中有_处用到了Redis:

- query
- taskcheck

# 9.心跳机制

编排系统和pod的运行是解耦的，通过心跳机制保持通信。心跳机制主要解决两种情况：

1. workflow终止，pod也要立即终止 
2. pod无法上传心跳，workflow终止

## 心跳表

task在运行过程中需要时刻向mojito传送心跳消息，这样mojito才能确保task的存活，是通过task端调用mojito-API，mojito写心跳表的方式完成的。心跳表大小："39091952"，3千万条数据

**心跳表内容如下**：
```go
type TaskCheck struct {
	CheckID      string         `json:"check_id" gorm:"unique_index"`  // 就是taskID
	Domain       string         `json:"domain"`
	TaskUUID     string         `json:"task_uuid"`	// 也是taskID
	WorkflowUUID string         `json:"workflow_uuid" gorm:"index"` 
	TaskName     string         `json:"task_name" gorm:"index"`
	WorkflowName string         `json:"workflow_name" gorm:"index"`
	PodName      string         `json:"pod_name" gorm:"index"`
	Status       string         `json:"status" gorm:"index"`
	Input        postgres.Jsonb `json:"input"`
	Output       postgres.Jsonb `json:"output"`
	CreatedAt    time.Time      `json:"created_at" gorm:"index"`
	UpdatedAt    time.Time      `json:"updated_at" gorm:"index"`
	ScheduledAt  time.Time      `json:"scheduled_at" gorm:"index"`
	ID           uint           `json:"id" gorm:"primary_key"`
}
```

**task_check很大，必须要加索引**

## 心跳逻辑

1. task开始，调用`register`注册心跳表(task_check)

2. task端开启子进程，每5s调用`updateTaskStatus` 

   updateTaskStatus包含两方面：

   1. **读：**每5s通过redis获取task_check 的 status（redis获取/缓存失效，pg获取，再加入redis）
   2. **写：**每60s（`time.Now()-updatedAt>60s`）向数据库和redis中写入task信息（**Status，UpdatedAt**）如果每5s直接写pg会造成巨大压力（只有status是 healthy/registered 才可以进行心跳表更新，失败就没必要更新）
   3. **为什么要60s更新一次数据库，但是却5s调用一次接口？直接60s调用一次接口不行吗**
      和pod的设计有关，当workflow被terminate的时候，为了保证task也能立刻结束，需要发送通知给pod。但是pod实际上是client而不是server，是无法接受请求的，只能通过调用心跳接口，根据response来确定是否要继续运行。如果pod发送心跳请求的间隔时间过长，workflow结束后pod无法立即得到通知，就会浪费资源。

3. mojito端开启goroutine，每隔一段时间对心跳表进行扫描，将stauts为"healthy","registered" 的task 但是`time.now()-updated_time>5min` 的视为心跳失败，更新他们的状态为time_out

4. reset/restart/retry/terminate 操作会删除redis，并将心跳表中的status置为terminate，之后task端再次每5s一次读取status时，将会返回terminate，从而pod内部自己结束

# 10.数据一致性

## Msubstatus与其存在的数据一致性问题

Msubstatus 记录业务层级上的workflow状态记录。一共分为以下几个状态：

- queuing -- workflow的某个task正在排队
- running -- workflow的某个task正在工作
- failed -- workflow因某task失败而整体失败
- timeout -- workflow因某个task心跳超时而失败
- terminate -- workflow终止
- completed -- workflow完成

Msubstatus存在数据一致问题，本质在于，已经结束的workflow无法继续接收到signal。如果workflow处于running状态，调用terminate将其终止并发信号将Msubstatus改为terminate，如果在信号处理之前workflow已经terminate，将无法再收到信号，Msubstatus将永远处于running，如下图：

<img src="https://tva1.sinaimg.cn/large/008i3skNgy1gw4jx3cw4pj30rw0h8q3b.jpg" alt="image-20211105161901971" style="zoom:50%;" />

# 11.pod停止

## reset后怎样停止

情况1：A--B--C(running)--D=====>reset至A（restart/retry同理）

情况2：A--B--C(running)--D=====>terminate  

此时C的pod怎样停下来?

触发此类操作时，会立即写表，将task的status改为failed。pod端再次发送心跳时，查询心跳表会返回心跳失败，从而终止

​	



